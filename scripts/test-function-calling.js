#!/usr/bin/env node

/**
 * Function Calling ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (Node.jsç‰ˆ)
 * 
 * ç›®çš„: å„LLMãƒ¢ãƒ‡ãƒ«ãŒFunction Callingã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‹ç¢ºèª
 * ãƒ†ã‚¹ãƒˆå¯¾è±¡:
 *  1. gpt-oss:20b
 *  2. qwen2.5-coder:7b
 *  3. mistral-nemo:12b
 *  4. deepseek-r1:7b
 *  5. qwen2.5:14b
 *  6. gemma2:27b
 */

const OLLAMA_BASE_URL = 'http://localhost:11434';

// ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ„ãƒ¼ãƒ«å®šç¾©
const tools = [
  {
    type: 'function',
    function: {
      name: 'read_file',
      description: 'ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿å–ã‚Šã¾ã™',
      parameters: {
        type: 'object',
        properties: {
          path: {
            type: 'string',
            description: 'ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆä¾‹: src/index.tsï¼‰',
          },
        },
        required: ['path'],
      },
    },
  },
  {
    type: 'function',
    function: {
      name: 'list_files',
      description: 'æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã¾ã™',
      parameters: {
        type: 'object',
        properties: {
          directory: {
            type: 'string',
            description: 'ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ï¼ˆä¾‹: srcï¼‰',
          },
        },
        required: ['directory'],
      },
    },
  },
];

// ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
const testModels = [
  'gpt-oss:20b',
  'qwen2.5-coder:7b',
  'mistral-nemo:12b',
  'deepseek-r1:7b',
  'qwen2.5:14b',
  'gemma2:27b',
];

/**
 * Ollamaã« Function Calling ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
 */
async function testFunctionCalling(modelName) {
  const requestBody = {
    model: modelName,
    messages: [
      {
        role: 'user',
        content: 'src/index.ts ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„',
      },
    ],
    tools: tools,
    stream: false,
  };

  try {
    console.log(`\nðŸ§ª Testing ${modelName}...`);
    
    const response = await fetch(`${OLLAMA_BASE_URL}/api/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`   âŒ HTTP Error: ${response.status}`);
      console.error(`   Response: ${errorText}`);
      return false;
    }

    const data = await response.json();
    
    // ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if (data.message?.tool_calls && data.message.tool_calls.length > 0) {
      console.log(`   âœ… SUCCESS: Function calling is supported!`);
      console.log(`   Tool called: ${data.message.tool_calls[0].function.name}`);
      console.log(`   Arguments:`, data.message.tool_calls[0].function.arguments);
      return true;
    } else {
      console.log(`   âš ï¸  FAILED: No tool calls detected`);
      console.log(`   Response content:`, data.message?.content?.substring(0, 150));
      return false;
    }
  } catch (error) {
    console.error(`   âŒ Error: ${error.message}`);
    return false;
  }
}

/**
 * åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
 */
async function getAvailableModels() {
  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`);
    const data = await response.json();
    return data.models?.map(m => m.name) || [];
  } catch (error) {
    console.error('Failed to fetch models:', error.message);
    return [];
  }
}

/**
 * sleepé–¢æ•°
 */
function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * ãƒ¡ã‚¤ãƒ³å‡¦ç†
 */
async function main() {
  console.log('ðŸš€ Function Calling Test Started');
  console.log('=====================================');
  
  // åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
  const availableModels = await getAvailableModels();
  console.log(`\nðŸ“¦ Available models in Ollama:`);
  availableModels.forEach(m => console.log(`   - ${m}`));

  const results = [];

  // å„ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ
  for (const model of testModels) {
    if (!availableModels.includes(model)) {
      console.log(`\nâ­ï¸  Skipping ${model} (not installed)`);
      continue;
    }

    const supported = await testFunctionCalling(model);
    results.push({ model, supported });
    
    // æ¬¡ã®ãƒ†ã‚¹ãƒˆã¾ã§å°‘ã—å¾…æ©Ÿ
    await sleep(1000);
  }

  // çµæžœã‚µãƒžãƒªãƒ¼
  console.log('\n\n=====================================');
  console.log('ðŸ“Š Test Results Summary');
  console.log('=====================================');
  
  const supportedModels = results.filter(r => r.supported);
  const unsupportedModels = results.filter(r => !r.supported);

  if (supportedModels.length > 0) {
    console.log('\nâœ… Supported Models:');
    supportedModels.forEach(r => console.log(`   - ${r.model}`));
  }

  if (unsupportedModels.length > 0) {
    console.log('\nâŒ Unsupported Models:');
    unsupportedModels.forEach(r => console.log(`   - ${r.model}`));
  }

  if (supportedModels.length === 0) {
    console.log('\nâš ï¸  WARNING: No models support Function Calling');
    console.log('   Please install one of the recommended models:');
    testModels.forEach(m => console.log(`   - ollama pull ${m}`));
  } else {
    console.log(`\nðŸŽ‰ ${supportedModels.length} model(s) ready for implementation!`);
    console.log(`   Recommended for use: ${supportedModels[0].model}`);
  }
}

// å®Ÿè¡Œ
main().catch(console.error);
