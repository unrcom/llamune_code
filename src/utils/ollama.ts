/**
 * Ollama API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
 * Ollama ã®ãƒ­ãƒ¼ã‚«ãƒ« API ã¨é€šä¿¡ã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
 */

import { spawn } from 'child_process';

// Ollama APIã®ãƒ™ãƒ¼ã‚¹URL
const OLLAMA_BASE_URL = 'http://localhost:11434';

/**
 * Ollama ãƒ¢ãƒ‡ãƒ«ã®å‹å®šç¾©
 */
export interface OllamaModel {
  name: string;
  modified_at: string;
  size: number;
  digest: string;
  details?: {
    format?: string;
    family?: string;
    parameter_size?: string;
    quantization_level?: string;
  };
}

/**
 * ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‹å®šç¾©
 */
export interface OllamaModelsResponse {
  models: OllamaModel[];
}

/**
 * Ollama API ã‚¨ãƒ©ãƒ¼
 */
export class OllamaError extends Error {
  constructor(
    message: string,
    public statusCode?: number
  ) {
    super(message);
    this.name = 'OllamaError';
  }
}

/**
 * ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
 */
export async function listModels(): Promise<OllamaModel[]> {
  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`);

    if (!response.ok) {
      throw new OllamaError(
        `Ollama API error: ${response.statusText}`,
        response.status
      );
    }

    const data = (await response.json()) as OllamaModelsResponse;
    return data.models || [];
  } catch (error) {
    if (error instanceof OllamaError) {
      throw error;
    }

    // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãªã©
    if (error instanceof Error) {
      throw new OllamaError(
        `Ollama ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: ${error.message}`
      );
    }

    throw new OllamaError('ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
  }
}

/**
 * Ollama ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
 */
export async function checkOllamaStatus(): Promise<boolean> {
  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {
      method: 'GET',
    });
    return response.ok;
  } catch {
    return false;
  }
}

/**
 * Ollama ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•
 */
export function startOllama(): void {
  const ollamaProcess = spawn('ollama', ['serve'], {
    detached: true,
    stdio: 'ignore',
  });

  // ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ‡ã‚Šé›¢ã—ã¦ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
  ollamaProcess.unref();
}

/**
 * Ollama ã®èµ·å‹•ã‚’å¾…æ©Ÿ
 * @param maxWaitSeconds æœ€å¤§å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
 * @param intervalMs ãƒã‚§ãƒƒã‚¯é–“éš”ï¼ˆãƒŸãƒªç§’ï¼‰
 */
export async function waitForOllama(
  maxWaitSeconds = 30,
  intervalMs = 500
): Promise<boolean> {
  const maxAttempts = (maxWaitSeconds * 1000) / intervalMs;
  let attempts = 0;

  while (attempts < maxAttempts) {
    const isRunning = await checkOllamaStatus();
    if (isRunning) {
      return true;
    }

    // æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§å¾…æ©Ÿ
    await new Promise((resolve) => setTimeout(resolve, intervalMs));
    attempts++;
  }

  return false;
}

/**
 * Ollama ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦èµ·å‹•
 * @returns èµ·å‹•æˆåŠŸã¾ãŸã¯æ—¢ã«èµ·å‹•ã—ã¦ã„ã‚‹å ´åˆã¯ true
 */
export async function ensureOllamaRunning(): Promise<boolean> {
  // ã¾ãšèµ·å‹•çŠ¶æ…‹ã‚’ç¢ºèª
  const isRunning = await checkOllamaStatus();
  if (isRunning) {
    return true;
  }

  // èµ·å‹•ã—ã¦ã„ãªã„å ´åˆã¯èµ·å‹•ã‚’è©¦ã¿ã‚‹
  console.log('ğŸš€ Ollama ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™...');
  startOllama();

  // èµ·å‹•ã‚’å¾…æ©Ÿ
  const started = await waitForOllama();
  if (started) {
    console.log('âœ… Ollama ãŒèµ·å‹•ã—ã¾ã—ãŸ');
    console.log('');
    return true;
  }

  return false;
}

/**
 * ãƒã‚¤ãƒˆæ•°ã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
 */
export function formatSize(bytes: number): string {
  const units = ['B', 'KB', 'MB', 'GB', 'TB'];
  let size = bytes;
  let unitIndex = 0;

  while (size >= 1024 && unitIndex < units.length - 1) {
    size /= 1024;
    unitIndex++;
  }

  return `${size.toFixed(1)} ${units[unitIndex]}`;
}

/**
 * ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’æŠ½å‡ºï¼ˆä¾‹: "9B" ã‹ã‚‰ "9.0B params"ï¼‰
 */
export function formatParams(model: OllamaModel): string {
  const paramSize = model.details?.parameter_size;
  if (paramSize) {
    return `${paramSize} params`;
  }
  return 'Unknown size';
}

/**
 * ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒ«ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰ã™ã‚‹
 * @param modelName ãƒ¢ãƒ‡ãƒ«åï¼ˆä¾‹: "gemma2:9b"ï¼‰
 * @returns ãƒ—ãƒ«æˆåŠŸæ™‚ã¯ true
 */
export function pullModel(modelName: string): Promise<boolean> {
  return new Promise((resolve, reject) => {
    console.log(`ğŸ“¥ ${modelName} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...`);
    console.log('');

    const pullProcess = spawn('ollama', ['pull', modelName], {
      stdio: ['inherit', 'pipe', 'pipe'],
    });

    // æ¨™æº–å‡ºåŠ›ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
    pullProcess.stdout?.on('data', (data) => {
      process.stdout.write(data.toString());
    });

    // ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
    pullProcess.stderr?.on('data', (data) => {
      process.stderr.write(data.toString());
    });

    pullProcess.on('close', (code) => {
      console.log('');
      if (code === 0) {
        console.log(`âœ… ${modelName} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ`);
        resolve(true);
      } else {
        console.error(`âŒ ${modelName} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ`);
        reject(new OllamaError(`ãƒ—ãƒ«å¤±æ•—: çµ‚äº†ã‚³ãƒ¼ãƒ‰ ${code}`));
      }
    });

    pullProcess.on('error', (error) => {
      console.error('âŒ ollama ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ');
      reject(new OllamaError(`ãƒ—ãƒ«å¤±æ•—: ${error.message}`));
    });
  });
}

/**
 * ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ã™ã‚‹
 * @param modelName ãƒ¢ãƒ‡ãƒ«åï¼ˆä¾‹: "gemma2:9b"ï¼‰
 * @returns å‰Šé™¤æˆåŠŸæ™‚ã¯ true
 */
export async function deleteModel(modelName: string): Promise<boolean> {
  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/delete`, {
      method: 'DELETE',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ name: modelName }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new OllamaError(
        `ãƒ¢ãƒ‡ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: ${errorText || response.statusText}`,
        response.status
      );
    }

    return true;
  } catch (error) {
    if (error instanceof OllamaError) {
      throw error;
    }

    if (error instanceof Error) {
      throw new OllamaError(`ãƒ¢ãƒ‡ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: ${error.message}`);
    }

    throw new OllamaError('ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
  }
}

/**
 * Chat ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‹å®šç¾©
 */
export interface ChatMessage {
  role: 'system' | 'user' | 'assistant' | 'tool';
  content: string;
  model?: string; // ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ï¼ˆassistantã®å ´åˆï¼‰
  tool_calls?: Array<{
    function: {
      name: string;
      arguments: Record<string, any>;
    };
  }>;
}

/**
 * Chat ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‹å®šç¾©
 */
export interface ChatParameters {
  temperature?: number;
  top_p?: number;
  top_k?: number;
  repeat_penalty?: number;
  num_ctx?: number;
  seed?: number;
}

/**
 * Chat ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‹å®šç¾©
 */
export interface ChatRequest {
  model: string;
  messages: ChatMessage[];
  stream?: boolean;
  options?: ChatParameters;
}

/**
 * Chat ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‹å®šç¾©ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
 */
export interface ChatResponse {
  model: string;
  created_at: string;
  message: ChatMessage;
  done: boolean;
}

/**
 * ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
 * @param modelName ãƒ¢ãƒ‡ãƒ«å
 * @param messages ä¼šè©±å±¥æ­´
 * @param onChunk ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒ³ã‚¯ã‚’å—ä¿¡ã—ãŸã¨ãã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
 * @param parameters ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒãƒ£ãƒƒãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
 */
export async function chatWithModel(
  modelName: string,
  messages: ChatMessage[],
  onChunk: (chunk: string) => void,
  parameters?: ChatParameters
): Promise<void> {
  const request: ChatRequest = {
    model: modelName,
    messages,
    stream: true,
  };

  // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¿½åŠ 
  if (parameters) {
    request.options = parameters;
  }

  try {
    const response = await fetch(`${OLLAMA_BASE_URL}/api/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(request),
    });

    if (!response.ok) {
      throw new OllamaError(
        `Chat API error: ${response.statusText}`,
        response.status
      );
    }

    if (!response.body) {
      throw new OllamaError('ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒœãƒ‡ã‚£ãŒã‚ã‚Šã¾ã›ã‚“');
    }

    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\n').filter((line) => line.trim());

      for (const line of lines) {
        try {
          const data = JSON.parse(line) as ChatResponse;
          if (data.message?.content) {
            onChunk(data.message.content);
          }
        } catch {
          // JSON ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        }
      }
    }
  } catch (error) {
    if (error instanceof OllamaError) {
      throw error;
    }

    if (error instanceof Error) {
      throw new OllamaError(`Chat ã‚¨ãƒ©ãƒ¼: ${error.message}`);
    }

    throw new OllamaError('ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
  }
}

/**
 * ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰æ¨å¥¨ num_ctx ã‚’å–å¾—
 */
export function getRecommendedNumCtx(modelName: string): number {
  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
  const DEFAULT_NUM_CTX = 8192;
  
  // ãƒ¢ãƒ‡ãƒ«åã®æ­£è¦åŒ–ï¼ˆã‚¿ã‚°ã‚’é™¤å»ï¼‰
  const baseName = modelName.split(':')[0];
  
  // ç‰¹å®šãƒ¢ãƒ‡ãƒ«ã®æ¨å¥¨å€¤ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå®Ÿæ¸¬å€¤ã®ã¿ï¼‰
  const contextMap: Record<string, number> = {
    'gpt-oss': 131072,        // ç¢ºèªæ¸ˆã¿: 131072
    'gemma2': 8192,           // ç¢ºèªæ¸ˆã¿: 8192
    'qwen2.5': 32768,         // ç¢ºèªæ¸ˆã¿: 32768
  };
  
  // ãƒãƒƒãƒ”ãƒ³ã‚°ã«å­˜åœ¨ã™ã‚Œã°ãã®å€¤ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
  return contextMap[baseName] ?? DEFAULT_NUM_CTX;
}
